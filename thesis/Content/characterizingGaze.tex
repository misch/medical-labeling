\chapter{Characterizing gaze}
\label{chap:characterizing-gaze}
This chapter will discuss the used setup and the quality of extracted positive labels gained from the observed gaze positions. The important question to answer is, how reliable our data is with respect to the assumption that gaze observation can naturally provide us with positive labels for the data. 

\section{Setup}
We used an affordable eye-tracking device called ``The Eye Tribe''. According to the producer's website (\url{http://dev.theeyetribe.com/general/}), the device has an accuracy of at least 1 degree visual angle. We placed the device on a tripod below a [?]-inch screen \todo{screen size} and observed the screen from a distance of approximately 60cm.  \todoWriteMore{tell that scans were converted to video sequences}

\begin{figure}[ht]
	\centering

	\includegraphics[width=\textwidth]{theeyetribe}	
	\caption{user in front of ``The Eye Tribe'' (image taken from \url{http://dev.theeyetribe.com/general/})}
	\label{fig:theeyetribe}
\end{figure}

The video sequences were played on full screen. In this setup, the minimum accuracy of 1 degree corresponds to an on-screen error of approximately 1cm. 
Figure \ref{fig:onedegreecircle} gives an idea of how much this error might mean in terms of our used datasets.
The instrument dataset is less sensitive to this than e.g.\ the cochlea CT scan that has fine structures to be recognized.

\begin{figure}[ht]
	\centering
	\begin{subfigure}[h]{0.31\textwidth}
		\includegraphics[width=\textwidth]{one-degree-circle-cochlea-17pix-frame195_small_new}	
		\caption*{cochlea}
	\end{subfigure}
	~
	\begin{subfigure}[h]{0.31\textwidth}
		\includegraphics[width=\textwidth]{one-degree-circle-instrument-18_62pix-frame195_small_new}
		\caption*{instrument}
	\end{subfigure}
	~
	\begin{subfigure}[h]{0.31\textwidth}
		\includegraphics[width=\textwidth]{one-degree-circle-eyeMRI-12_28pix-frame46_small}	
		\caption*{eye tumor}
	\end{subfigure}
	\caption{Visual illustration of how much error a 1 degree visual angle causes in the different datasets using our described setup. Whereas most parts of the instrument are big in size, the fine structures in the images of the cochlea or the eye tumor might not be hit by the measured gaze position, even when an expert is looking exactly at them.}
	\label{fig:onedegreecircle}
\end{figure}

Vilari\~no et al. suggested to explore the analysis of gaze fixation patterns and voice labeling in future studies. 
In this project we want to focus on the other issues of their approach described in Chapter \ref{chap:background}. 
Therefore, we stick with their appoach and asked the user to press a key when an important structure / object is appearing in the video and to focus on the actual important object. 
Note that therefore, what is presented in this work, is an active application of eye-tracking with the potential to become passive in the future.

\section{Reliability of gaze observations}
Given some ground truth data (datasets ``instrument'', ``cochlea'', ``eye tumor''), we evaluated if the assumption of Vilari\~no et al.\ is valid, that only ``positive positions'' are hit by the gaze whenever the observer indicates (by pressing a key) that he sees a structure of interest. 
As the user had the task to focus on the object in the video, we expected that the majority of recorded gaze positions are located at true positives, or that at least some true positive points can be found within a 1 degree visual angle of the recorded gaze position. 
Clearly, the smaller the structures, the less likely it was that a true positive was hit. 
We tried here to separate the human from the measurement error by investigating, for each dataset, the actual distance between the gaze position and the closest true positive point. 
Values above 1 degree visual angle clearly mean human error whereas values below could mean human error or measurement error. 
To get a first idea of the actual measurement error, the gaze positions were measured and evaluated on a very simple dataset; a video of a non-moving black point on white background in the middle of the screen. 
Two measurements were taken. Figure \ref{fig:gazeMeasurementAccuracy} shows that for the task of staring at this black dot, the errors remain well below 1 degree, except in the case of blinking. 
The distance to the actual center of the image is on average between 5 and 7 pixels in this test video; this corresponds to a visual angle of approximately 0.25 to 0.4 degrees.

\begin{figure}[ht]
	\centering
	\begin{subfigure}[h]{0.41\textwidth}
	      \setlength{\fboxsep}{0pt}%
	      \setlength{\fboxrule}{0.5pt}%
	      \centering
	      \fbox{\includegraphics[width=\textwidth]{gazeMeasurementAccuracy2D.pdf}}
	\end{subfigure}
	~
	\begin{subfigure}[h]{0.48\textwidth}
		\includegraphics[width=\textwidth]{gazeMeasurementAccuracy1D.pdf}	
		%\caption{}
	\end{subfigure}
	\caption{For the task of staring at the black dot in the middle of the screen, the errors remain well below 1 degree. Blinking causes considerable outliers. The mean distance to the actual center of the image (dotted blue and green lines) is between 5 and 7 pixels in this test video; this corresponds to a visual angle of approximately 0.25 to 0.4 degrees.}
	\label{fig:gazeMeasurementAccuracy}
\end{figure}


\begin{figure}[ht]
	  \includegraphics[width=0.5\textwidth]{closestPositiveDataset2vid2.pdf}
	  \includegraphics[width=0.5\textwidth]{closestPositiveDataset2vid5.pdf}
	  \includegraphics[width=0.5\textwidth]{closestPositiveDataset2vid4.pdf}
	  \includegraphics[width=0.5\textwidth]{closestPositiveDataset2vid3.pdf}
	  \caption{instrument: As expected, many values are exactly zero which means that hitting the object is rather easy in this dataset. Where the gaze is not on the object, the typically big outlier values in the distance indicate that this is not due to a measurement error, but instead the eye was really not on the object.}
	\label{fig:distanceToClosestPositiveD2}
\end{figure}

\begin{figure}[ht]
	  \includegraphics[width=0.5\textwidth]{closestPositiveDataset7vid1.pdf}
	  \includegraphics[width=0.5\textwidth]{closestPositiveDataset7vid4.pdf}
	  \includegraphics[width=0.5\textwidth]{closestPositiveDataset7vid6.pdf}
	  \includegraphics[width=0.5\textwidth]{closestPositiveDataset7vid7.pdf}
	  \caption{eye tumor: The little amount of available values means that, in general, the structure of interest (tumor) is small in size (not available values mean that there are no positive values in the ground truth frame). Between frames 40 and 50 the tumor seems to be well visible and big enough in size to be rather reliably hit by the gaze.}
	\label{fig:distanceToClosestPositiveD7}
\end{figure}

\begin{figure}[ht]
	  \includegraphics[width=0.5\textwidth]{closestPositiveDataset8vid3.pdf}
	  \includegraphics[width=0.5\textwidth]{closestPositiveDataset8vid6.pdf}
	  \includegraphics[width=0.5\textwidth]{closestPositiveDataset8vid7.pdf}
	  \includegraphics[width=0.5\textwidth]{closestPositiveDataset8vid1.pdf}
	  \caption{cochlea: In this dataset, it is rather rare that the object of interest (cochlea) is actually hit by the measured gaze positions; only in few cases the distance is exactly zero. The high variation in distance to the object indicates that it is hard to follow the fine structures with the eyes, and probably only a small part of the error might be caused by inaccuracy in the measurements.}
	\label{fig:distanceToClosestPositiveD8}
\end{figure}


\begin{figure}[ht]
	  \includegraphics[width=0.5\textwidth]{fractionsDataset2vid2.pdf}
	  \includegraphics[width=0.5\textwidth]{fractionsDataset2vid5.pdf}
	  \includegraphics[width=0.5\textwidth]{fractionsDataset2vid4.pdf}
	  \includegraphics[width=0.5\textwidth]{fractionsDataset2vid3.pdf}
	  
	  \centering
	  \includegraphics[width=0.5\textwidth]{fraction-legend}
	  \caption{instrument: using SLIC superpixels}
	\label{fig:positiveFractionD6}
\end{figure}

\begin{figure}[ht]
	  \includegraphics[width=0.5\textwidth]{fractionsDataset7vid1.pdf}
	  \includegraphics[width=0.5\textwidth]{fractionsDataset7vid4.pdf}
	  \includegraphics[width=0.5\textwidth]{fractionsDataset7vid6.pdf}
	  \includegraphics[width=0.5\textwidth]{fractionsDataset7vid7.pdf}
	  
	  \centering
	  \includegraphics[width=0.5\textwidth]{fraction-legend}
	  \caption{eye tumor: using SLIC superpixels}
	\label{fig:positiveFractionD7}
\end{figure}

\begin{figure}[ht]
	  \includegraphics[width=0.5\textwidth]{fractionsDataset8vid3.pdf}
	  \includegraphics[width=0.5\textwidth]{fractionsDataset8vid6.pdf}
	  \includegraphics[width=0.5\textwidth]{fractionsDataset8vid7.pdf}
	  \includegraphics[width=0.5\textwidth]{fractionsDataset8vid1.pdf}
	  
	  \centering
	  \includegraphics[width=0.5\textwidth]{fraction-legend}
	  \caption{cochlea: using SLIC superpixels}
	\label{fig:positiveFractionD8}
\end{figure}

Therefore, giving a tolerance of 0.4 degrees seems to be a necessary step to account for the inaccuracy of the eye-tracking device. 
The experiments in Figures \ref{fig:distanceToClosestPositiveD2}, \ref{fig:distanceToClosestPositiveD7} and \ref{fig:distanceToClosestPositiveD8} show that, however, also giving this tolerance is no guarantee that each recorded gaze position will be indicating a true positive position. 
In fact, the instrument dataset (Figure \ref{fig:distanceToClosestPositiveD2}) shows rather promising results: 
In the four recorded gaze sequences, the majority of the values are exactly zero, indicating that the gaze hit the actual object. 
Measurement errors do not seem to influence the potential accuracy of our method here, as the cases where the gaze is not on the object are mostly clear outliers with a distance of more than 0.4 degrees visual angle. 
A similar conclusion holds for the eye tumor dataset (Figure \ref{fig:distanceToClosestPositiveD7}). 
The gaze observations show that between frames 40 and 50, when the tumor is big in size, it is well hit by the gaze. 
There are, best visible in the top left figure, some positions that are slightly off the object before frame 47. 
This might be a measurement error, but more likely, it is because the gaze has not yet settled at the correct position. 
The rather big distances to any positive pixels before and after this interval reflect the fact that the size of the structure of interest decreases rapidly in these frames. 
The recordings from the cochlea dataset shown in Figure \ref{fig:distanceToClosestPositiveD8} suggest, especially the observations shown in the two upper plots between frames 150 and 160\todo{explain WHY this is suggested by the plots}, that some positive information could be gained by considering additional nearby points of the recorded gaze position.
However, most of the measurements show that it is actually a rather rare event in this dataset, that the gaze really hits the object. 
The variation in distance to the object and the nature of this dataset (fine structures that are rapidly changing over time / depth) indicates that it is either hard to find, or then hard to follow the actual cochlea parts with the eyes, if not both. 
This can clearly be considered the most challenging dataset used for this project.
In this dataset, considering that the data within a 0.4 degrees visual angle is positive, would clearly increase the probability to assign real positive data to the actual gaze observations. 
However, the total area ot the positives is in most of the frames very small compared to the whole image (see e.g.\ Figure ...). 
Therefore we pay the high price of including a lot of noise into the positive training set, in some cases maybe more noise than actual positive data.

\section{Include a certain tolerance}
\todo{\"uberleitung fehlt... maybe consider the following as ``ways to give this tolerance''}Even when staring exactly on the object, not all of the superpixel's content is necessarily positive. 
This can e.g.\ be seen in the Figures \ref{fig:positiveFractionD7} and \ref{fig:positiveFractionD8} where the structures are sometimes so small that well-regularized SLIC-superpixels cannot capture them. 
In this case, reducing the size of the superpixels would help to overcome the issue. 
However, if the gaze drifts away from the object only by a few pixels, then the positive content of the superpixels dramatically decreases. 
This issue could be overcome by considering more of the surrounding superpixels to be positive (and therefore find the ``correct'' one but also introduce noise to the positively labeled data), i.e.\ giving a certain tolerance. 
Increasing the size of the superpixels is another possibility that will help, but it is paid with accuracy at the object boundaries and, because SLIC still aims at respecting the edges in the image, the true positive superpixels will typically first extend towards the direction that will not include the wrong gaze position, assuming that this lies on the other side of a strong image edge (see Figure \ref{fig:gazeOffSuperpixelSize}).

\begin{figure}[ht]
	\centering
	\begin{subfigure}[h]{0.31\textwidth}
	      \includegraphics[width=\textwidth]{superpixelSize1instrument}
	\end{subfigure}
	~
	\begin{subfigure}[h]{0.31\textwidth}
		\includegraphics[width=\textwidth]{superpixelSize2instrument}	
		%\caption{}
	\end{subfigure}
	~
	\begin{subfigure}[h]{0.31\textwidth}
		\includegraphics[width=\textwidth]{superpixelSize3instrument}	
		%\caption{}
	\end{subfigure}	
	
	\vspace{3mm}
	\begin{subfigure}[h]{0.31\textwidth}
	      \includegraphics[width=\textwidth]{superpixelSize1eye_20px}
	\end{subfigure}
	~
	\begin{subfigure}[h]{0.31\textwidth}
		\includegraphics[width=\textwidth]{superpixelSize2eye_30px}	
		%\caption{}
	\end{subfigure}
	~
	\begin{subfigure}[h]{0.31\textwidth}
		\includegraphics[width=\textwidth]{superpixelSize3eye_100px}	
		%\caption{}
	\end{subfigure}	
	\caption{Extending the superpixel size does not necessarily help to overcome the wrong or inaccurate gaze positions, as the superpixels naturally tend to respect edges and the gaze is in this case usually on the wrong side of the edge. Yellow: gaze position that is slightly off from the object}
	\label{fig:gazeOffSuperpixelSize}
\end{figure}
[kinda conclusion:]
Clearly, the simple assumption that all the user-indicated positive labels are true positives, is not valid. 
Even the rather simple case of the surgical instrument leads to noise in the acquired positive labels. The finer the structures of interest, the less reliably the gaze positions indicate true positive information. 
The problems could be overcome by [list different ways of given tolerances (e.g.\ gaussian prob. of being positive / a fixed radius within which the data are considered positive / superpixel size]. 
\todoWriteMore{if have time: try some things with smoothed gaze!}
\todoWriteMore{maybe add tolerance plots?}
