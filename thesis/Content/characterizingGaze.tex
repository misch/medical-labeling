\chapter{Characterizing gaze}
\label{chap:characterizing-gaze}
This chapter will discuss the used setup and the quality of extracted positive labels gained from the observed gaze positions. The important question to answer is, how reliable our data are with respect to the assumption that gaze observation can naturally provide us with positive labels for the data. 

\section{Setup}
We used an affordable eye-tracking device called ``The Eye Tribe''. 
According to the producer's website (\url{http://dev.theeyetribe.com/general/}), the device has an accuracy of at least 1 degree visual angle. We placed the device on a tripod below a 32.4cm\,$\times$\,51.8cm screen and observed the screen from a distance of approximately 60cm (an illustration of the setup can be seen in Figure \ref{fig:theeyetribe}).

\begin{figure}[ht]
	\centering

	\includegraphics[width=\textwidth]{theeyetribe}	
	\caption{user in front of ``The Eye Tribe'' (image taken from \url{http://dev.theeyetribe.com/general/})}
	\label{fig:theeyetribe}
\end{figure}

The video sequences were played on full screen at 30 frames per second. 
The 3D scans were converted to a video and played at 10 frames per second. 
In this setup, the minimum accuracy of 1 degree corresponds to an on-screen error of approximately 1cm. 
Figure \ref{fig:onedegreecircle} gives an idea of how much this error might mean in terms of our used datasets. 
The instrument dataset is less sensitive to this than e.g.\ the cochlea CT scan that has fine structures to be recognized.

\begin{figure}[ht]
	\centering
	\begin{subfigure}[h]{0.31\textwidth}
		\includegraphics[width=\textwidth]{one-degree-circle-cochlea-17pix-frame195_small_new}	
		\caption*{cochlea}
	\end{subfigure}
	~
	\begin{subfigure}[h]{0.31\textwidth}
		\includegraphics[width=\textwidth]{one-degree-circle-instrument-18_62pix-frame195_small_new}
		\caption*{instrument}
	\end{subfigure}
	~
	\begin{subfigure}[h]{0.31\textwidth}
		\includegraphics[width=\textwidth]{one-degree-circle-eyeMRI-12_28pix-frame46_small}	
		\caption*{eye tumor}
	\end{subfigure}
	\caption{Visual illustration of how much error a 1 degree visual angle causes in the different datasets using our described setup. Whereas most parts of the instrument are big in size, the fine structures in the images of the cochlea or the eye tumor might not be hit by the measured gaze position, even when an expert is looking exactly at them.}
	\label{fig:onedegreecircle}
\end{figure}

Vilari\~no et al. suggested to explore the analysis of gaze fixation patterns and voice labeling in future studies. 
In this project we want to focus on the other issues of their approach described in Chapter \ref{chap:background}. 
Therefore, we stick with their appoach and asked the user to press a key when an important structure / object is appearing in the video and to focus on the actual important object. 
Note that therefore, what is presented in this work, is an active application of eye-tracking with the potential to become passive in the future.

\section{Reliability of gaze observations}
Given some ground truth data (datasets ``instrument'', ``cochlea'', ``eye tumor''), we evaluated if the assumption of Vilari\~no et al.\ is valid, that only ``positive positions'' are hit by the gaze whenever the observer indicates (by pressing a key) that he sees a structure of interest. 
As the user had the task to focus on the object in the video, we expected that the majority of recorded gaze positions are located at true positives, or that at least some true positive points can be found within a 1 degree visual angle of the recorded gaze position. 
\todo{move to end: Clearly, the smaller the structures, the less likely it was that a true positive was hit.}
We tried here to separate the human from the measurement error by investigating, for each dataset, the actual distance between the gaze position and the closest true positive point. 
Values above 1 degree visual angle clearly mean human error whereas values below could mean human error or measurement error. 
To get a first idea of the actual measurement error, the gaze positions were measured and evaluated on a very simple dataset; a video of a non-moving black point on white background in the middle of the screen. 
Two measurements were taken. Figure \ref{fig:gazeMeasurementAccuracy} shows that for the task of staring at this black dot, the errors remain well below 1 degree, except in the case of blinking. 
The distance to the actual center of the image is on average between 5 and 7 pixels in this test video; this corresponds to a visual angle of approximately 0.25 to 0.4 degrees.

\begin{figure}[ht]
	\centering
	\begin{subfigure}[h]{0.41\textwidth}
	      \setlength{\fboxsep}{0pt}%
	      \setlength{\fboxrule}{0.5pt}%
	      \centering
	      \fbox{\includegraphics[width=\textwidth]{gazeMeasurementAccuracy2D.pdf}}
	\end{subfigure}
	~
	\begin{subfigure}[h]{0.48\textwidth}
		\includegraphics[width=\textwidth]{gazeMeasurementAccuracy1D.pdf}	
		%\caption{}
	\end{subfigure}
	\caption{For the task of staring at the black dot in the middle of the screen, the errors remain well below 1 degree. Blinking causes considerable outliers. The mean distance to the actual center of the image (dotted blue and green lines) is between 5 and 7 pixels in this test video; this corresponds to a visual angle of approximately 0.25 to 0.4 degrees.}
	\label{fig:gazeMeasurementAccuracy}
\end{figure}


\begin{figure}[ht]
	  \includegraphics[width=\textwidth]{closestPositiveDataset2vid2.eps}
	  \includegraphics[width=\textwidth]{closestPositiveDataset2vid5.eps}
	  \includegraphics[width=\textwidth]{closestPositiveDataset2vid4.eps}
	  
	  \vspace{3mm}
	  \includegraphics[width=\textwidth]{size_instrument.eps}
	  \caption{instrument: As expected, many values are exactly zero which means that hitting the object is rather easy in this dataset. Where the gaze is not on the object, the typically big outlier values in the distance indicate that this is not due to a measurement error, but instead the eye was really not on the object.}
	\label{fig:distanceToClosestPositiveD2}
\end{figure}

\begin{figure}[ht]
	  \includegraphics[width=\textwidth]{closestPositiveDataset7vid1.eps}
	  \includegraphics[width=\textwidth]{closestPositiveDataset7vid4.eps}
	  \includegraphics[width=\textwidth]{closestPositiveDataset7vid6.eps}
	  
	  \vspace{3mm}
	  \includegraphics[width=\textwidth]{size_eyetumor.eps}	  
	  \caption{eye tumor: The little amount of available values means that, in general, the structure of interest (tumor) is small in size (not available values mean that there are no positive values in the ground truth frame). Between frames 40 and 50 the tumor seems to be well visible and big enough in size to be rather reliably hit by the gaze. Note that in frames 50 -- 54 the size of the tumor is still considerably big, but the gaze positions are getting off the object already from frame 50 on. This indicates the not only the actual size but also the change rate of size has an effect on the quality of the gaze positions.}
	\label{fig:distanceToClosestPositiveD7}
\end{figure}

\begin{figure}[ht]
	  \includegraphics[width=\textwidth]{closestPositiveDataset8vid3.eps}
	  \includegraphics[width=\textwidth]{closestPositiveDataset8vid6.eps}
	  \includegraphics[width=\textwidth]{closestPositiveDataset8vid7.eps}
	  
	  \vspace{3mm}
	  \includegraphics[width=\textwidth]{size_cochlea.eps}	  
	  \caption{cochlea: In this dataset, it is rather rare that the object of interest (cochlea) is actually hit by the measured gaze positions; only in few cases the distance is exactly zero. The high variation in distance to the object indicates that it is hard to follow the fine structures with the eyes, and probably only a small part of the error might be caused by inaccuracy in the measurements. Note that as in Figure \ref{fig:distanceToClosestPositiveD7}, we can observe that the rate of change in object size is related to the distance of gaze positions to true positive pixels. Especially the part between frame 150 and 200 is interesting. Even the little period (frames 173-187) of size fluctuations before the peak at frame 192 seems to cause considerable increases in the distance plots above.}
	\label{fig:distanceToClosestPositiveD8}
\end{figure}

Therefore, giving a tolerance of 0.4 degrees seems to be a necessary step to account for the inaccuracy of the eye-tracking device. The top three plots of Figures \ref{fig:distanceToClosestPositiveD2}, \ref{fig:distanceToClosestPositiveD7} and \ref{fig:distanceToClosestPositiveD8} show for each dataset the distances to the closest true positive pixel for three different recorded gaze sequences. 
The instrument dataset (Figure \ref{fig:distanceToClosestPositiveD2}) shows rather promising results: 
In the three recorded gaze sequences, the majority of the values are exactly zero, indicating that the gaze hits the actual object. 
Measurement errors do not seem to influence the potential accuracy of our method here, as the cases where the gaze is not on the object are clear human-caused outliers with a distance of more than 1 degree visual angle.
A similar conclusion holds for the eye tumor dataset (Figure \ref{fig:distanceToClosestPositiveD7}). 
The gaze observations show that between frames 40 and 50, when the tumor is big in size, it is well hit by the gaze. 
The rather big distances to any positive pixels before and after this interval might reflect the fact that the size of the structure of interest decreases rapidly in these frames (see the last plot in Figure \ref{fig:distanceToClosestPositiveD7}). 
The recordings from the cochlea dataset (Figure \ref{fig:distanceToClosestPositiveD8}) show that it is actually a rather rare event in this dataset that the gaze really hits the object. However, the distance to the true positives stays mostly below 1 degree visual angle. This suggests that in this case, the inaccuracy of the device might be a problem.
Yet, considering the previously discussed measurements, it is more likely that the errors are due to the very fine structures to detect in this dataset: Like in the previous case of the eye tumor, the gaze accuracy decreases when the size of the object decreases. 
It seems that not only the object size is of importance when trying to fixate positive points, but also the change rate of the size: In all the three datasets, but best visible for the eye tumor and cochlea, it can be seen that the gaze tends to drift away from the object whenever the size of the object decreases, whereas an increasing size seems to attract the attention of the observer and make it much easier to focus the object. \todo{maybe play the video backwards?}
The discussed plots show that the cochlea dataset can clearly be considered the most challenging one used during this project because it is the one where the gaze sequences are the least focused on the object. 
The rate of change in size, but also the absolute size seem to be critical when trying to focus an object throughout a sequence of images. Figure \ref{fig:relativeobjectsize} and Table \ref{tab:avgobjectsize} illustrate comparisons of the object sizes among the different datasets. Considering the relative sizes\footnote{The relative object size was calculated with respect to the resolution of the used images.}, it is very obvious that dataset 2 will be less prone to little errors in the gaze than the other two datasets because the likelihood to randomly find a positive pixel in dataset 2 is much higher.

\begin{figure}[ht]
	\centering
	  \includegraphics[width=\textwidth]{size_relative.png}
	\caption{1)\,--\,3) Object areas in \#pixels for the three available datasets. Note that the eye tumor and cochlea are visible only for a rather short number of frames and for both of them the size decreases very rapidly towards the end. 4) Object areas relative to the resolution of the image frames. The small relative area of the eye tumor and the cochlea in the scans may explain the difficulties to hit the object with the gaze.}
	\label{fig:relativeobjectsize}
\end{figure}

\begin{table}[ht]
	\centering
	  \caption{A listing of the sizes of the structures of interest, averaged over all the frames of a dataset that contain positive information.}
	  \label{tab:avgobjectsize}
	\begin{tabular}{ | c  c  c  c | }
	\hline
				& instrument 	& eye tumor & cochlea \\ \hline
	  resolution  		& $576 \times 720$ & $380 \times 384$ & $526 \times 429$ \\ 
	  average area [px]	& $39378$ 	& $981.12$ 	 & $605.86$ \\
	  average rel. area [\%]& $9.5$ 		& $0.67$ 		 & $0.2685$ \\ \hline
	\end{tabular}
\end{table}

Having considered possible causes for the gaze positions not being focused on the object, we will now briefly focus on the effects of that problem with respect to our later task of using the gaze positions to generate positive training samples. 
To check how much true positive / false positive information we are actually using for our work, we visualized the amount of positive information in the following way: 
For each frame where the user pressed a key, we extracted the superpixel that contains the corresponding gaze position. 
Each of the extracted superpixels contains many pixels and we calculated the relative amount of true positive pixels among them. 
A reason for those superpixels containing less than 100\% true positive pixels is that some of the extracted superpixel describes a region that does not contain the object at all. 
This would lead to a fraction of 0\% true positives. 
The other reason is that the gaze actually hits the object, but the corresponding superpixel contains other information than just the object. 
For the same three gaze sequences than before, the relative amount of positive information in each extracted superpixel is shown in Figures \ref{fig:positiveFractionD2}, \ref{fig:positiveFractionD7} and \ref{fig:positiveFractionD8}. 
We can see in Figure \ref{fig:positiveFractionD2} that even a small distance to the actual object can cause considerable noise in the extracted superpixels. 
For example for the first sequence, there are some extracted superpixels containing less than 50\% positive information around frame 400, even though we saw in Figure \ref{fig:distanceToClosestPositiveD2} that the distance between the gaze and the actual object was greater than zero during only 5 frames and not bigger than 2.5 pixels. 
This is not a very surprising observation, as the used SLIC superpixels respect edges. 
Therefore, the superpixel containing a position that is not exactly on the object will typically not contain any positive information. Furthermore, this does not necessarily change with the superpixel size, as the examples in Figure \ref{fig:gazeOffSuperpixelSize} show. On the other hand, the effects of a similar case in the second sequence around frame 320 are not so dramatic and clearly, the extracted superpixels contain more true positive than false positive information, which is a promising precondition for our later task. 
For the eye tumor and the cochlea data, the situation is more critical. Figures \ref{fig:positiveFractionD7} and \ref{fig:positiveFractionD8} show that we will effectively have to deali with a large amount of wrong information. In fact, more of the extracted ``positive'' superpixels contain less than 50\% of true positive information, and even more severely, for both datasets, quite some superpixels contain only negative information that we wrongly assume to be positive.

\begin{figure}[ht]
	  \includegraphics[width=\textwidth]{fractionsDataset2vid2.eps}
	  \includegraphics[width=\textwidth]{fractionsDataset2vid5.eps}	  
	  \includegraphics[width=\textwidth]{fractionsDataset2vid4.eps}
	  
	  \centering
	  \includegraphics[width=\textwidth]{fraction-legend.eps}
	  \caption{instrument: fraction of positive information within superpixels }
	\label{fig:positiveFractionD2}
\end{figure}

\begin{figure}[ht]
	  \includegraphics[width=\textwidth]{fractionsDataset7vid1.eps}
	  \includegraphics[width=\textwidth]{fractionsDataset7vid4.eps}
	  \includegraphics[width=\textwidth]{fractionsDataset7vid6.eps}
	  
	  \centering
	  \includegraphics[width=\textwidth]{fraction-legend.eps}
	  \caption{eye tumor: using SLIC superpixels}
	\label{fig:positiveFractionD7}
\end{figure}

\begin{figure}[ht]
	  \includegraphics[width=\textwidth]{fractionsDataset8vid3.eps}
	  \includegraphics[width=\textwidth]{fractionsDataset8vid6.eps}
	  \includegraphics[width=\textwidth]{fractionsDataset8vid7.eps}
	  
	  \centering
	  \includegraphics[width=\textwidth]{fraction-legend.eps}
	  \caption{cochlea: using SLIC superpixels}
	\label{fig:positiveFractionD8}
\end{figure}

\begin{figure}[ht]
	\centering
	\begin{subfigure}[h]{0.31\textwidth}
	      \includegraphics[width=\textwidth]{superpixelSize1instrument}
	\end{subfigure}
	~
	\begin{subfigure}[h]{0.31\textwidth}
		\includegraphics[width=\textwidth]{superpixelSize2instrument}	
		%\caption{}
	\end{subfigure}
	~
	\begin{subfigure}[h]{0.31\textwidth}
		\includegraphics[width=\textwidth]{superpixelSize3instrument}	
		%\caption{}
	\end{subfigure}	
	
	\vspace{3mm}
	\begin{subfigure}[h]{0.31\textwidth}
	      \includegraphics[width=\textwidth]{superpixelSize1eye_20px}
	\end{subfigure}
	~
	\begin{subfigure}[h]{0.31\textwidth}
		\includegraphics[width=\textwidth]{superpixelSize2eye_30px}	
		%\caption{}
	\end{subfigure}
	~
	\begin{subfigure}[h]{0.31\textwidth}
		\includegraphics[width=\textwidth]{superpixelSize3eye_100px}	
		%\caption{}
	\end{subfigure}	
	\caption{Extending the superpixel size does not necessarily help to overcome the wrong or inaccurate gaze positions, as the superpixels naturally tend to respect edges and the gaze is in this case usually on the wrong side of the edge. Yellow: gaze position that is slightly off from the object}
	\label{fig:gazeOffSuperpixelSize}
\end{figure}


Clearly, the simple assumption that all the user-indicated positive labels are true positives, is not valid. 
For the instrument data, we could show that we still gain more true than false positive information from the gaze information. However, the finer the structures of interest, the less reliably the gaze positions indicate true positives, as was clearly visible in Figures \ref{fig:positiveFractionD7} and \ref{fig:positiveFractionD8}.