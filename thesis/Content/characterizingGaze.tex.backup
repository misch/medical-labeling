\chapter{Characterizing gaze}
\label{chap:characterizing-gaze}
This chapter will discuss the used setup and the quality of extracted positive labels gained from the observed gaze positions. The important question to answer is, how reliable our data is with respect to the assumption that gaze observation can naturally provide us with positive labels in the data. 

\section{Setup}
We used an affordable eye-tracking device called ``The Eye Tribe''. According to the producer's website (\url{http://dev.theeyetribe.com/general/}), the device has an accuracy of at least 1 degree visual angle. We placed the device on a tripod below a [?]-inch screen \todo{screen size} and observed the screen from a distance of approximately 60cm. The video sequences were played on full screen. In this setup, the minimum accuracy of 1 degree corresponds to an on-screen error of approximately 1cm. Figure \ref{fig:onedegreecircle} shows that this has a significant influence on our performance, depending on the actual dataset. The instrument dataset is less sensitive to this than e.g.\ the cochlea CT scan that has fine structures to be recognized.

\begin{figure}[ht]
	\centering
	\begin{subfigure}[h]{0.31\textwidth}
		\includegraphics[width=\textwidth]{one-degree-circle-cochlea-17pix-frame195_small_new}	
		%\missingfigure[figwidth=\textwidth]{}
		\caption*{cochlea}
	\end{subfigure}
	~
	\begin{subfigure}[h]{0.31\textwidth}
		\includegraphics[width=\textwidth]{one-degree-circle-instrument-18_62pix-frame195_small_new}	
		%\missingfigure[figwidth=\textwidth]{}
		\caption*{instrument}
	\end{subfigure}
	~
	\begin{subfigure}[h]{0.31\textwidth}
		\includegraphics[width=\textwidth]{one-degree-circle-eyeMRI-12_28pix-frame46_small}	
		%\missingfigure[figwidth=\textwidth]{}
		\caption*{eye tumor}
	\end{subfigure}
	\caption{Visual illustration of how much error a 1 degree visual angle causes in the different datasets using our described setup. Whereas most parts of the instrument are big in size, the fine structures in the images of the cochlea or the eye tumor might not be hit by the measured gaze position, even when an expert is looking exactly at them.}
	\label{fig:onedegreecircle}
\end{figure}

Vilari\~no et al. suggested to explore the analysis of gaze fixation patterns and voice labeling. In this project, we wanted to focus on the other issues of their approach described in Chapter \ref{chap:background}. Therefore, we stick with their appoach of asking the user to press a key when an important structure / object is appearing in the video. More precisely, we asked the user to look at the actual important object. Note that therefore, what is presented in this work, is an active application of eye-tracking with the potential to be improved to become passive.

\section{some title...}
%\section{Validation}
Given some ground truth data (datasets ``instrument'', ``cochlea'', ``eye tumor''), we evaluated if the assumption of Vilari\~no et al. \todo{did they really state this assumption?} is reasonable, that only ``positive positions'' are hit by the gaze whenever the observer indicates (by pressing a key) that he sees a structure of interest. 
As the observer had the task to observe the object in the video, we expected that the majority of recorded gaze positions (when the observer pressed the key) are located at true positives, or that at least some true positive points can be found within a 1 degree visual angle of the recorded gaze position. 
Clearly, the smaller the structures, the less likely it was that a true positive was hit. 
We tried here to separate the human from the measurement error by investigating, for each dataset, the actual distance between the gaze position and the closest true positive point. 
Values above 1 degree visual angle clearly mean human error whereas values below could mean human error or measurement error. 
The results can be seen in Figures \ref{fig:distanceToClosestPositiveD2}, \ref{fig:distanceToClosestPositiveD7} and \ref{fig:distanceToClosestPositiveD8}. 
To get a first idea of the actual measurement error \todo{don't call it this way! maybe error that is not ``human staring at the wrong position''}, the gaze positions were measured and evaluated on a very simple dataset; a video of a non-moving black point on white background in the middle of the screen. 
Two measurements were taken. Figure \ref{fig:gazeMeasurementAccuracy} shows that for the task of staring at this black dot, the errors remain well below 1 degree, except in the case of blinking. 
However, the distance to the actual center of the image is on average between 5 and 7 pixels in this test video; this corresponds to a visual angle of approximately 0.25 to 0.4 degrees.

\begin{figure}[ht]
	\centering
	\begin{subfigure}[h]{0.41\textwidth}
	      \setlength{\fboxsep}{0pt}%
	      \setlength{\fboxrule}{0.5pt}%
	      \centering
	      \fbox{\includegraphics[width=\textwidth]{gazeMeasurementAccuracy2D.pdf}}
	\end{subfigure}
	~
	\begin{subfigure}[h]{0.48\textwidth}
		\includegraphics[width=\textwidth]{gazeMeasurementAccuracy1D.pdf}	
		%\caption{}
	\end{subfigure}
	\caption{For the task of staring at the black dot in the middle of the screen, the errors remain well below 1 degree. Blinking causes considerable outliers. The mean distance to the actual center of the image (dotted blue and green lines) between 5 and 7 pixels in this test video; this corresponds to a visual angle of approximately 0.25 to 0.4 degrees.}
	\label{fig:gazeMeasurementAccuracy}
\end{figure}


\begin{figure}[ht]
	  \includegraphics[width=0.5\textwidth]{closestPositiveDataset2vid2.pdf}
	  \includegraphics[width=0.5\textwidth]{closestPositiveDataset2vid5.pdf}
	  \includegraphics[width=0.5\textwidth]{closestPositiveDataset2vid4.pdf}
	  \includegraphics[width=0.5\textwidth]{closestPositiveDataset2vid3.pdf}
	  \caption{instrument: As expected, many values are exactly zero which means that hitting the object is rather easy in this dataset. Where the gaze is not on the object, the typically big outlier values in the distance indicate that this is not due to a measurement error, but instead the eye was really not on the object.}
	\label{fig:distanceToClosestPositiveD2}
\end{figure}

\begin{figure}[ht]
	  \includegraphics[width=0.5\textwidth]{closestPositiveDataset7vid1.pdf}
	  \includegraphics[width=0.5\textwidth]{closestPositiveDataset7vid4.pdf}
	  \includegraphics[width=0.5\textwidth]{closestPositiveDataset7vid6.pdf}
	  \includegraphics[width=0.5\textwidth]{closestPositiveDataset7vid7.pdf}
	  \caption{eye tumor: The little amount of available values means that, in general, the structure of interest (tumor) is small in size (not available values mean that there are no positive values in the ground truth frame). Between frames 40 and 50 the tumor seems to be well visible and big enough in size to be rather reliably hit by the gaze.}
	\label{fig:distanceToClosestPositiveD7}
\end{figure}

\begin{figure}[ht]
	  \includegraphics[width=0.5\textwidth]{closestPositiveDataset8vid3.pdf}
	  \includegraphics[width=0.5\textwidth]{closestPositiveDataset8vid6.pdf}
	  \includegraphics[width=0.5\textwidth]{closestPositiveDataset8vid7.pdf}
	  \includegraphics[width=0.5\textwidth]{closestPositiveDataset8vid1.pdf}
	  \caption{cochlea: In this dataset, is rather rare that the object of interest (cochlea) is actually hit by the measured gaze positions; only in few cases the distance is exactly zero. The high variation in distance to the object indicates that it is hard to follow the fine structures with the eyes, and probably only a small part of the error might be caused by inaccuracy in the measurements.}
	\label{fig:distanceToClosestPositiveD8}
\end{figure}


\begin{figure}[ht]
	  \includegraphics[width=0.5\textwidth]{fractionsDataset2vid2.pdf}
	  \includegraphics[width=0.5\textwidth]{fractionsDataset2vid5.pdf}
	  \includegraphics[width=0.5\textwidth]{fractionsDataset2vid4.pdf}
	  \includegraphics[width=0.5\textwidth]{fractionsDataset2vid3.pdf}
	  
	  \centering
	  \includegraphics[width=0.5\textwidth]{fraction-legend}
	  \caption{instrument: using SLIC superpixels}
	\label{fig:positiveFractionD6}
\end{figure}

\begin{figure}[ht]
	  \includegraphics[width=0.5\textwidth]{fractionsDataset7vid1.pdf}
	  \includegraphics[width=0.5\textwidth]{fractionsDataset7vid4.pdf}
	  \includegraphics[width=0.5\textwidth]{fractionsDataset7vid6.pdf}
	  \includegraphics[width=0.5\textwidth]{fractionsDataset7vid7.pdf}
	  
	  \centering
	  \includegraphics[width=0.5\textwidth]{fraction-legend}
	  \caption{eye tumor: using SLIC superpixels}
	\label{fig:positiveFractionD7}
\end{figure}

\begin{figure}[ht]
	  \includegraphics[width=0.5\textwidth]{fractionsDataset8vid3.pdf}
	  \includegraphics[width=0.5\textwidth]{fractionsDataset8vid6.pdf}
	  \includegraphics[width=0.5\textwidth]{fractionsDataset8vid7.pdf}
	  \includegraphics[width=0.5\textwidth]{fractionsDataset8vid1.pdf}
	  
	  \centering
	  \includegraphics[width=0.5\textwidth]{fraction-legend}
	  \caption{cochlea: using SLIC superpixels}
	\label{fig:positiveFractionD8}
\end{figure}


%\section{Gain more information}
From Figure \ref{fig:gazeMeasurementAccuracy} we learn that, giving a tolerance of 0.4 degrees is a necessary step to account for the inaccuracy of the eye-tracking device. The experiments in Figures \ref{fig:distanceToClosestPositiveD2}, \ref{fig:distanceToClosestPositiveD7} and \ref{fig:distanceToClosestPositiveD8} show that, however, also giving this tolerance is no guarantee that each recorded gaze position will be a correctly indicating a true positive position. At the same time, a bigger tolerance within data is considered positive will also lead to more noise. Even when staring exactly on the object, not all of the superpixel's content is necessarily positive. This can e.g.\ be seen in the Figures \ref{fig:positiveFractionD7} and \ref{fig:positiveFractionD8} where the structures are sometimes so small that well-regularized SLIC-superpixels cannot capture them. In this case, reducing the size of the superpixels would help to overcome the issue. However, if the gaze drifts away from the object only by a few pixels, then the positive content of the superpixels dramatically decreases. Thiss issue could be overcome by considering more of the surrounding superpixels to be positive (and therefore find the ``correct'' one but also introduce noise to the positively labeled data), i.e.\ giving a certain tolerance. Increasing the size of the superpixels is another possibility that will help, but it is paid with accuracy at the object boundaries and, because SLIC still aims at respecting the edges in the image, the true positive superpixels will typically first extend towards the direction that will not include the wrong gaze position, assuming that this lies on the other side of a strong image edge (see Figure \ref{fig:gazeOffSuperpixelSize}).


\begin{figure}[ht]
	\centering
	\begin{subfigure}[h]{0.31\textwidth}
	      \includegraphics[width=\textwidth]{superpixelSize1instrument}
	\end{subfigure}
	~
	\begin{subfigure}[h]{0.31\textwidth}
		\includegraphics[width=\textwidth]{superpixelSize2instrument}	
		%\caption{}
	\end{subfigure}
	~
	\begin{subfigure}[h]{0.31\textwidth}
		\includegraphics[width=\textwidth]{superpixelSize3instrument}	
		%\caption{}
	\end{subfigure}	
	
	\vspace{3mm}
	\begin{subfigure}[h]{0.31\textwidth}
	      \includegraphics[width=\textwidth]{superpixelSize1eye_20px}
	\end{subfigure}
	~
	\begin{subfigure}[h]{0.31\textwidth}
		\includegraphics[width=\textwidth]{superpixelSize2eye_30px}	
		%\caption{}
	\end{subfigure}
	~
	\begin{subfigure}[h]{0.31\textwidth}
		\includegraphics[width=\textwidth]{superpixelSize3eye_100px}	
		%\caption{}
	\end{subfigure}	
	\caption{Extending the superpixel size does not necessarily help to overcome the wrong or inaccurate gaze positions, as the superpixels naturally tend to respect edges and the gaze is in this case usually on the wrong side of the edge. Yellow: gaze position that is slightly off from the object}
	\label{fig:gazeOffSuperpixelSize}
\end{figure}


\todoWriteMore{plots from Finnnnland, tolerances, inherent noise in negative labelsne, also some noise in positive labels, etc. }
\todoWriteMore{put somewhere: Assuming we have only positive gaze positions, we still don't have the gatives yet $\rightarrow$ PU approach}