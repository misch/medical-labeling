# Towards Passive Labeling in 3D via Gaze Observation
This repository contains the material for my Master's Thesis at Universit√§t Bern. It was done in coop The project aims at generating segmentations in medical images using eye-tracking data from clinicians.

# Assumed file-structure
The MATLAB-code assumes the following data structure:

- matlab code/ 
- NIfTI_20140122/
  - [matlab toolbox to read NIfTI format](http://ch.mathworks.com/matlabcentral/fileexchange/8797-tools-for-nifti-and-analyze-image)
- vlfeat/
  - [vlfeat library](http://www.vlfeat.org/)
- libsvm-3.20/
  - libsvm-3.20/
    - matlab/
      - [compiled libsvm binaries for matlab](https://www.csie.ntu.edu.tw/~cjlin/libsvm/)
- sqb-0.1/
  - [gradient boosting framework](https://sites.google.com/site/carlosbecker/resources/gradient-boosting-boosted-trees)
- data/
  - Dataset1/
    - Video.avi (the input video)
    - gaze-measurements/ (the recorded gaze positions in csv format -- **refer to Section "Gaze observations"**)
      - (...).csv
    - input-frames/ (single frames of the input video in png format)
      - frame_00001.png
      - frame_00002.png
      - ...
    - ground_truth-frames/ (ground truth segmentations for the single frames of the input video in png format)
      - frame_00001.png
      - frame_00002.png
      - ...
    - (...)-descriptors/ (generated by MATLAB code)
      - frame_00001.mat
      - frame_00002.mat
      - ...
    - trainingSet.mat (generated by MATLAB code)

  - Dataset2
    - Video.avi
    - ...
  - ...

# Gaze observations #
The csv file containing gaze records should have the following structure (columns):

    frame; time; visible; x; y

- **frame:** the frame number
- **time (not currently needed):** the time of the measurement [ms from start of video] to detect whether some positions are 'old records' (it is not currently used in the project and could therefore be left blank)
- **visible:** 1, if the user pressed the space bar during the frame, 0 otherwise - in the code, this value is usually called *key_pressed*
- **x, y:** x- and y-positions as outputted by The Eye Tribe in relative screen coordinates (floats between [0,1])

So, an example file would look as follows:

    0; 0; 0; 0.431286; 0.412303
    1; 33; 0; 0.431181; 0.413398
    2; 66; 0; 0.430746; 0.414175
    ...
    158; 5129; 1; 0.779511; 0.382291
    159; 5163; 1; 0.780631; 0.381369

# MATLAB code #
The MATLAB code is organized as follows:

- **main.m:** the main script contains the necessary MATLAB sections to execute, if you want to try out the whole procedure
- **classification/** contains functions used for the classification part; that is everything that is used in the main-script from step 5) onwards.
- **prepareData/** contains a script "prepareData" that is called in the main-script, and most of the functions that are used in it. Also the functions to generate features can be found there.
- **pugradboost/** contains the functions and a test-script for gradient boosting with the PU-loss function. The current implementation has decision stumps as weak learner.
- **subtightplot/** contains the subtightplot toolbox to create subplots without big margins. It was publish on Mathworks [File Exchange](http://www.mathworks.com/matlabcentral/fileexchange/39664-subtightplot)
- **utils/** contains simple functions that make the life easier and don't belong to one specific step
- **visualizations/** contains scripts and functions used to generate all kinds of visualizations that have been used in the thesis. Some require to first load certain data into the workspace. All this is indicated in the descriptions of the single scripts of functions.
